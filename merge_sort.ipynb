{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8a07189",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Magics to load test framework and imports.\n",
    "%load djl_imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e33da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NDManager is a factory class to produce n-dimensional arrays.\n",
    "// Think of these as PyTorch tensors.\n",
    "NDManager manager = NDManager.newBaseManager();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d9f7e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Classical merge sort\n",
    "public class MergeSort {\n",
    "    public static int[] sort(int[] nums) {\n",
    "        if (nums.length == 1) {\n",
    "            return nums;\n",
    "        }\n",
    "\n",
    "        int mid = nums.length / 2;\n",
    "        int[] left = new int[mid];\n",
    "        int[] right = new int[nums.length - mid];\n",
    "\n",
    "        for (int i = 0; i < left.length; i++) {\n",
    "            left[i] = nums[i];\n",
    "        }\n",
    "        for (int i = 0; i < right.length; i++) {\n",
    "            right[i] = nums[mid + i];\n",
    "        }\n",
    "\n",
    "        left = sort(left);\n",
    "        right = sort(right);\n",
    "\n",
    "        return merge(left, right);\n",
    "\n",
    "        }\n",
    "\n",
    "    public static int[] merge(int[] left, int[] right) {\n",
    "        int[] result = new int[left.length + right.length];\n",
    "\n",
    "        int leftInd = 0;\n",
    "        int rightInd = 0;\n",
    "        int resultInd = 0;\n",
    "\n",
    "        while (leftInd < left.length || rightInd < right.length) {\n",
    "            if (leftInd < left.length && rightInd < right.length) {\n",
    "                if (left[leftInd] < right[rightInd]) {\n",
    "                    result[resultInd++] = left[leftInd++];\n",
    "                } else {\n",
    "                    result[resultInd++] = right[rightInd++];\n",
    "                }\n",
    "            } else if (leftInd < left.length) {\n",
    "                result[resultInd++] = left[leftInd++];\n",
    "            } else if (rightInd < right.length) {\n",
    "                result[resultInd++] = right[rightInd++];\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return result;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f59dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "int[] t1In       = new int[]{974, 100, 34, 700, -1, 555, 832};\n",
    "int[] t1Expected = new int[]{-1, 34, 100, 555, 700, 832, 974};\n",
    "\n",
    "int[] result = MergeSort.sort(t1In);\n",
    "Assert.assertArrayEquals(result, t1Expected);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8acf0819",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Now try to soften it!\n",
    "public class DifferentiableMergeSort {\n",
    "    public static NDArray softMerge(NDArray left, NDArray right) {\n",
    "        NDArray merged = manager.create(new float[(int)left.size() + (int)right.size()]);\n",
    "        int i = 0;\n",
    "        int j = 0;\n",
    "        int k = 0;\n",
    "        \n",
    "        while (i < left.size() && j < right.size()) {\n",
    "            NDArray scores = manager.create(new float[]{left.getFloat(i), right.getFloat(j)});\n",
    "            NDArray weights = scores.softmax(/*axis=*/0).toType(left.getDataType(), false);\n",
    "\n",
    "            float mergedElement = weights.getFloat(0) * left.getFloat(i) + weights.getFloat(1) * right.getFloat(j);\n",
    "            merged.setScalar(new NDIndex(k++), mergedElement);\n",
    "\n",
    "            i += (weights.getFloat(0) > 0.5) ? 1 : 0;\n",
    "            j += (weights.getFloat(1) > 0.5) ? 1 : 0;\n",
    "        }\n",
    "\n",
    "        if (i < left.size()) {\n",
    "            merged.set(new NDIndex(k + \":\" + (k + left.size() - i)), left.get(new NDIndex(i + \":\")));\n",
    "        }\n",
    "        if (j < right.size()) {\n",
    "           merged.set(new NDIndex(k + \":\" + (k + right.size() - j)), right.get(new NDIndex(j + \":\")));\n",
    "        }\n",
    "\n",
    "        return merged;\n",
    "    }\n",
    "\n",
    "    public static NDArray sort(NDArray arr) {\n",
    "        if (arr.size() <= 1) {\n",
    "            return arr;\n",
    "        }\n",
    "\n",
    "        int mid = (int) arr.size() / 2;\n",
    "        NDArray leftHalf = sort(arr.get(new NDIndex(\":\" + mid)));\n",
    "        NDArray rightHalf = sort(arr.get(new NDIndex(mid + \":\")));\n",
    "\n",
    "        return softMerge(leftHalf, rightHalf);\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c86a48cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 0.020709705\n",
      "LOSS: 0.028915882\n",
      "LOSS: 0.045237254\n",
      "LOSS: 0.057474326\n",
      "LOSS: 0.0741292\n",
      "LOSS: 0.08631287\n",
      "LOSS: 0.098490715\n",
      "LOSS: 0.11066332\n",
      "LOSS: 0.122830965\n",
      "LOSS: 0.13868037\n",
      "=================\n",
      "RESULT: \n",
      "ND: (5) cpu() float32 hasGradient\n",
      "[233.84  ,  83.18  ,  10.1149,   4.7815,   0.98  ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.commons.lang3.tuple.Pair;\n",
    "import java.util.ArrayList;\n",
    "import ai.djl.training.optimizer.*;\n",
    "\n",
    "float learningRate = 0.1f;\n",
    "NDArray t1In       = manager.create(new float[]{10.f, 234.f, 1.f, 83.f, 5.f});\n",
    "NDArray t1Expected = manager.create(new float[]{234.f, 83.f, 10.f, 5.f, 1.f});\n",
    "\n",
    "// Only one test case for now.\n",
    "ArrayList<Pair<NDArray, NDArray>> testCases = new ArrayList();\n",
    "testCases.add(Pair.of(t1In, t1Expected));\n",
    "\n",
    "// TODO: Try to introduce a bug in the merge sort implementation above. We may have to make everything a parameter.\n",
    "// Then perhaps set up a neural net to generate test cases and tune it on the normal implementation.\n",
    "for (Pair<NDArray, NDArray> pair : testCases) {\n",
    "    NDArray test = pair.getLeft();\n",
    "    NDArray result = manager.create(test.getShape());\n",
    "    test.setRequiresGradient(true);\n",
    "\n",
    "    // Training loop\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "        result = DifferentiableMergeSort.sort(test);\n",
    "        result.setRequiresGradient(true);\n",
    "        // Create a new gradient collector - these need to be made each training iteration\n",
    "        try (GradientCollector gc = Engine.getInstance().newGradientCollector()) {\n",
    "            NDArray loss = Loss.l1Loss().evaluate(new NDList(/*expected=*/pair.getRight()), new NDList(result));\n",
    "\n",
    "            // TODO: Verify that this is actually autodiffing through the merge sort.\n",
    "            // It seems like we might be just changing the input.\n",
    "            gc.backward(loss);\n",
    "\n",
    "            print(\"LOSS: \" + loss.getFloat());\n",
    "        } catch(Exception e) {\n",
    "            e.printStackTrace();\n",
    "        }\n",
    "        // Update the loss via result params (gradient descent)\n",
    "        // This actually is increasing the loss since we are doing SGD\n",
    "        // on the input itself... something is wrong.\n",
    "        test.subi(result.getGradient().mul(learningRate)); \n",
    "\n",
    "        // Clear gradients otherwise memory creeps\n",
    "        test.getGradient().close();\n",
    "        result.getGradient().close();\n",
    "    }\n",
    "    print(\"=================\");\n",
    "    print(\"RESULT: \");\n",
    "    print(result);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0b379e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "11.0.16+8-post-Ubuntu-0ubuntu120.04"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
